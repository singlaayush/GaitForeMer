{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#from sklearn.model_selection import StratifiedKFold, LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data for training or inference are formatted as a NumPy array in five dimensions (N, C, T, V, M):\n",
    "\n",
    "N: The number of sequences  # N = 164\n",
    "\n",
    "C: The number of input channels  # 3\n",
    "\n",
    "T: The maximum sequence length in frames  # variable lengths expected\n",
    "\n",
    "V: The number of joint points  # should be 25 for us\n",
    "\n",
    "M: The number of persons.  # should be 1 for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from 73 SMPL+H joints to 25 NTU-RGBD joints (1-base)\n",
    "# SMPL+H to NTU-RGBD Order (borrowed from: smpl_to_nturgbd() in https://github.com/abhinanda-punnakkal/BABEL/blob/main/action_recognition/data_gen/dutils.py)\n",
    "# Note 1: 'spine'/'spine1' = 3/6 -> 2 = 'middle of the spine' (only one spine joint recorded in NTU)\n",
    "# Note 2: 12, 22, 23, 24 and 25 NTU joints are approximations. The mappings below were made by BABEL.\n",
    "# more details in SMPLH_JOINT_NAMES.py in the humor_dev folder.\n",
    "_MAJOR_JOINTS = [\n",
    "                    0, 3,               # 1 - base of the spine, 2 - middle of the spine\n",
    "                    12, 15,             # 3 - neck, 4 - head\n",
    "                    16, 18, 20, 22,     # [5,  6,  7,  8]  - left hand\n",
    "                    17, 19, 21, 37,     # [9, 10, 11, 12]  - right hand\n",
    "                    1,  4,  7, 10,      # [13, 14, 15, 16] - left leg\n",
    "                    2,  5,  8, 11,      # [17, 18, 19, 20] - right leg\n",
    "                    9,                  # 21 - spine\n",
    "                    63, 64,             # 22-tip of the left hand 23-left thumb\n",
    "                    68, 69              # 24-tip of the right hand 25-right thumb\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_dict = joblib.load(\"/home/ayushsingla/humor_dev/data/clinical/all_joints_smplh_vtx.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645, 25, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(joints_dict['001'])                     # (T, V', C) = (645, 73, 3). Note: V' is 73 cause joints are 0-indexed and run from 0 to 72.\n",
    "np.shape(joints_dict['001'][:,_MAJOR_JOINTS,:])  # (T, V, C)  = (645, 25, 3). Joints are now in NTU-RGBD order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Frequency Counts:\n",
      " [[  0 141]\n",
      " [  1  23]]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/ayushsingla/humor_dev/GaitForeMer/data/labels/\"\n",
    "def data_generator(data_dict, csv_file):\n",
    "    df = pd.read_csv(Path(data_dir) / csv_file)\n",
    "    X_1 = []\n",
    "    Y = []\n",
    "    for key in data_dict.keys():\n",
    "        p = np.copy(data_dict[key][:,_MAJOR_JOINTS,:])\n",
    "        label = int(df.loc[df['ID'] == int(key)]['Y'].values[0])\n",
    "        X_1.append(p)\n",
    "        Y.append(label)\n",
    "    X_nd = np.array(X_1, dtype=object)\n",
    "    return X_nd, np.stack(Y), data_dict.keys()\n",
    "\n",
    "csv_file = \"binary_combined.csv\"\n",
    "data_dict = joblib.load(\"/home/ayushsingla/humor_dev/data/clinical/all_joints_smplh_vtx.pkl\") \n",
    "X_nd, Y, X_indices = data_generator(data_dict, csv_file)\n",
    "unique, counts = np.unique(Y, return_counts=True)\n",
    "print(\"Label Frequency Counts:\\n\", np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ayushsingla/humor_dev/data/clinical/all_joints_ntu_w_lbl.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((X_nd, Y), Path(\"/home/ayushsingla/humor_dev/data/clinical/\") / f\"all_joints_ntu_w_lbl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/ayushsingla/humor_dev/HD-GCN/data/clinical/data_indices.txt\", list(X_indices), fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run /home/ayushsingla/humor_dev/HD-GCN/data/clinical/seq_transformation.ipynb after the above cell is executed. Cells below are EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.17021277, 7.17391304])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "165 / np.bincount(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 469.8536585365854; STD: 127.31635477790033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {np.mean([x.shape[0] for x in X_nd])}; STD: {np.std([x.shape[0] for x in X_nd])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 294; max: 1148\n"
     ]
    }
   ],
   "source": [
    "print(f\"min: {np.min([x.shape[0] for x in X_nd])}; max: {np.max([x.shape[0] for x in X_nd])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X_nd, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  train len=147\n",
      "  test len=17\n",
      "Fold 1:\n",
      "  train len=147\n",
      "  test len=17\n",
      "Fold 2:\n",
      "  train len=147\n",
      "  test len=17\n",
      "Fold 3:\n",
      "  train len=147\n",
      "  test len=17\n",
      "Fold 4:\n",
      "  train len=148\n",
      "  test len=16\n",
      "Fold 5:\n",
      "  train len=148\n",
      "  test len=16\n",
      "Fold 6:\n",
      "  train len=148\n",
      "  test len=16\n",
      "Fold 7:\n",
      "  train len=148\n",
      "  test len=16\n",
      "Fold 8:\n",
      "  train len=148\n",
      "  test len=16\n",
      "Fold 9:\n",
      "  train len=148\n",
      "  test len=16\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path(f\"/home/ayushsingla/humor_dev/GaitForeMer/data/smpl_k_fold/{Path(csv_file).stem}\")\n",
    "data_folder.mkdir(exist_ok=True)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_nd, Y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  train len={len(train_index)}\")\n",
    "    print(f\"  test len={len(test_index)}\")\n",
    "    train = X_nd[train_index], Y[train_index]\n",
    "    test = X_nd[test_index], Y[test_index]\n",
    "    joblib.dump(train, f\"{data_folder}/train{i}.pkl\")\n",
    "    joblib.dump(test, f\"{data_folder}/test{i}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sanity Check flattening last two axes for seq_transformation in HD-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nd, Y = joblib.load(\"/home/ayushsingla/humor_dev/data/clinical/all_joints_ntu_w_lbl.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0851932  -0.41286176  4.450547  ]\n",
      " [ 0.08118555 -0.5047138   4.513398  ]\n",
      " [ 0.05033259 -0.89866716  4.4876175 ]\n",
      " [ 0.04640254 -0.947069    4.4222918 ]\n",
      " [ 0.22923806 -0.8132663   4.445941  ]\n",
      " [ 0.3293384  -0.5747096   4.434816  ]\n",
      " [ 0.29247358 -0.39668292  4.2684436 ]\n",
      " [ 0.24091506 -0.34315658  4.1957636 ]\n",
      " [-0.11833104 -0.78749985  4.4843783 ]\n",
      " [-0.21322793 -0.5529443   4.4856257 ]\n",
      " [-0.243857   -0.35799032  4.3276205 ]\n",
      " [-0.21572524 -0.30160886  4.2479115 ]\n",
      " [ 0.15981266 -0.3294887   4.4197707 ]\n",
      " [ 0.2362887  -0.19321965  4.080019  ]\n",
      " [ 0.23311287  0.19501826  4.164399  ]\n",
      " [ 0.2438674   0.23691681  4.0385528 ]\n",
      " [ 0.01993255 -0.32228684  4.427219  ]\n",
      " [-0.08823486 -0.12825552  4.1168346 ]\n",
      " [-0.06997121  0.2296868   4.2895117 ]\n",
      " [-0.08776293  0.2857036   4.169641  ]\n",
      " [ 0.06915653 -0.68338203  4.4602284 ]\n",
      " [ 0.18079185 -0.37087047  4.192755  ]\n",
      " [ 0.21754795 -0.29847914  4.1363974 ]\n",
      " [-0.15907481 -0.34073126  4.220185  ]\n",
      " [-0.2113055  -0.2511987   4.1881433 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_nd[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0851932 , -0.41286176,  4.450547  ,  0.08118555, -0.5047138 ,\n",
       "        4.513398  ,  0.05033259, -0.89866716,  4.4876175 ,  0.04640254,\n",
       "       -0.947069  ,  4.4222918 ,  0.22923806, -0.8132663 ,  4.445941  ,\n",
       "        0.3293384 , -0.5747096 ,  4.434816  ,  0.29247358, -0.39668292,\n",
       "        4.2684436 ,  0.24091506, -0.34315658,  4.1957636 , -0.11833104,\n",
       "       -0.78749985,  4.4843783 , -0.21322793, -0.5529443 ,  4.4856257 ,\n",
       "       -0.243857  , -0.35799032,  4.3276205 , -0.21572524, -0.30160886,\n",
       "        4.2479115 ,  0.15981266, -0.3294887 ,  4.4197707 ,  0.2362887 ,\n",
       "       -0.19321965,  4.080019  ,  0.23311287,  0.19501826,  4.164399  ,\n",
       "        0.2438674 ,  0.23691681,  4.0385528 ,  0.01993255, -0.32228684,\n",
       "        4.427219  , -0.08823486, -0.12825552,  4.1168346 , -0.06997121,\n",
       "        0.2296868 ,  4.2895117 , -0.08776293,  0.2857036 ,  4.169641  ,\n",
       "        0.06915653, -0.68338203,  4.4602284 ,  0.18079185, -0.37087047,\n",
       "        4.192755  ,  0.21754795, -0.29847914,  4.1363974 , -0.15907481,\n",
       "       -0.34073126,  4.220185  , -0.2113055 , -0.2511987 ,  4.1881433 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nd[0][0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_75 = np.array([x.reshape(x.shape[0], -1) for x in X_nd], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_75[0][0] == X_nd[0][0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 75)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_75[10].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "170361a79b2b9da3ff797fb2a74ac726c520765226abd2c932b224a86f1d7acf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
